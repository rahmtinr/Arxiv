{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.594639865997 0.482412060302\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "#Two people get to the same macro name but have different bodies and see who wins the fight\n",
    "df = pd.read_csv('/home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/RawOutput/Body/2_to_1_learning-unique_authorPair_nosmart.txt')\n",
    "df.columns = map(lambda x : x.replace(\" \", \"\") , df.columns)\n",
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= 0.75\n",
    "train = df[df['is_train'] == True]\n",
    "test = df[df['is_train'] == False]\n",
    "\n",
    "train_features = train.ix[:, df.columns.difference(['Label', 'is_train'])]\n",
    "train_labels = train['Label']\n",
    "test_features = test.ix[:, df.columns.difference(['Label', 'is_train'])]\n",
    "test_labels = test['Label']\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(test_features)\n",
    "print accuracy_score(test_labels, predictions), (sum(test_labels) - len(test_labels)) / float(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.621693121693 0.515873015873\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree\n",
    "#Two people get to the same macro body but have different names and see who wins the fight\n",
    "df = pd.read_csv('/home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/RawOutput/2_to_1_Exactly2Authors/2_to_1_learning-unique_authorPair_nosmart.txt')\n",
    "df.columns = map(lambda x : x.replace(\" \", \"\") , df.columns)\n",
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= 0.75\n",
    "train = df[df['is_train'] == True]\n",
    "test = df[df['is_train'] == False]\n",
    "\n",
    "train_features = train.ix[:, df.columns.difference(['Label', 'is_train'])]\n",
    "train_labels = train['Label']\n",
    "test_features = test.ix[:, df.columns.difference(['Label', 'is_train'])]\n",
    "test_labels = test['Label']\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(test_features)\n",
    "print accuracy_score(test_labels, predictions), (sum(test_labels) - len(test_labels)) / float(len(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [('BetweenCentLocal2', 0.55277), ('LocalFracChange2', -0.54195), ('GlobalCurExp2', -0.53657), ('GlobalCurExp1', 0.48289), ('LocalFracChange1', 0.46993), ('LocalDegree2', -0.37706), ('MacroNameLength1', 0.19543), ('IsMin2', -0.14876), ('IsMin1', 0.14876), ('IsMax1', -0.10416), ('IsMax2', 0.10416), ('MacroNameLength2', -0.09851), ('MacroBodyLength', -0.08412), ('LocalCurExp2', 0.02681), ('BetweenCentLocal1', 0.01005), ('LocalDegree1', -0.00759), ('LocalCurExp1', 0.00236), ('CurlyBraceMaxDepth', 0.0), ('NumberOfBackSlashes', 0.0), ('NumberOfDollarSigns', 0.0)] ['0.14579']\n",
      "\n",
      "Accuracy:  0.657407407407\n",
      "Majority:  0.518518518519\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "#Logistic Regression\n",
    "#Two people get to the same macro name but have different bodies and see who wins the fight\n",
    "#body fight - visible fight\n",
    "df = pd.read_csv('/home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/RawOutput/Body/2_to_1_learning-unique_authorPair_nosmart.txt')\n",
    "df.columns = map(lambda x : x.replace(\" \", \"\") , df.columns)\n",
    "labels = df['Label'] - 1\n",
    "#header = df.columns \n",
    "#df = preprocessing.scale(df.ix[:,df.columns.difference(['Label'])])\n",
    "header = list(set(df.columns) - set(['BetweenCentGlobal2', 'BetweenCentGlobal1', 'GlobalDegree2', 'IsMostRecent1', 'IsMostRecent2',\n",
    "                                     'GlobalDegree1', 'Label', 'CoAuthorCountUsedMacro1', 'CoAuthorCountUsedMacro2']))\n",
    "df = preprocessing.scale(df.ix[:, header])\n",
    "#header = ['GlobalCurExp1', 'GlobalCurExp2']\n",
    "#df = preprocessing.scale(df.ix[:, header])\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "test_features = []\n",
    "test_labels = []\n",
    "\n",
    "for index, features in enumerate(df):\n",
    "    my_rand = np.random.uniform(0, 1)\n",
    "    if my_rand <= 0.8:\n",
    "        train_features.append(features)\n",
    "        train_labels.append(labels[index])\n",
    "    else:\n",
    "        test_features.append(features)\n",
    "        test_labels.append(labels[index])\n",
    "\n",
    "logistic = LogisticRegression(C=1e5)\n",
    "logistic.fit(train_features, train_labels)\n",
    "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
    "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
    "        \n",
    "predictions = logistic.predict(test_features)\n",
    "temp = [\"%.5f\" % v for v in logistic.coef_[0]]\n",
    "five_decimals = [float(i) for i in temp]\n",
    "five_decimals_intercept = [\"%.5f\" % logistic.intercept_]\n",
    "five_decimals = sorted(zip(header, five_decimals), key=lambda x: -abs(x[1]))\n",
    "five_decimals_intercept = [\"%.5f\" % logistic.intercept_]\n",
    "print 'Coefficients: ', five_decimals, five_decimals_intercept\n",
    "print \"\"\n",
    "print \"Accuracy: \",  accuracy_score(test_labels, predictions)\n",
    "print \"Majority: \", max(1 - sum(test_labels) / float(len(test_labels)), sum(test_labels) / float(len(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Coefficients:  [('LocalFracChange2', -0.61317), ('GlobalCurExp2', -0.5452), ('LocalFracChange1', 0.4029), ('GlobalCurExp1', 0.37569), ('LocalDegree2', -0.27573), ('LocalDegree1', 0.21502), ('MacroNameLength2', -0.11577), ('BetweenCentLocal1', 0.10788), ('IsMin2', -0.10169), ('IsMin1', 0.10169), ('IsMax1', -0.10097), ('IsMax2', 0.10097), ('NumberOfBackSlashes', -0.07289), ('BetweenCentLocal2', -0.06219), ('MacroNameLength1', 0.05604), ('MacroBodyLength', -0.04845), ('LocalCurExp1', -0.04571), ('CurlyBraceMaxDepth', 0.03997), ('LocalCurExp2', -0.01083), ('NumberOfDollarSigns', 0.00465)] ['-0.01809']\n",
      "Accuracy:  0.657142857143\n",
      "Majority:  0.526984126984\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "#Logistic Regression\n",
    "#Two people get to the same macro body but have different names and see who wins the fight\n",
    "#name fight - Low visibility fights\n",
    "df = pd.read_csv('/home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/RawOutput/2_to_1_Exactly2Authors/2_to_1_learning-unique_authorPair_nosmart.txt')\n",
    "df.columns = map(lambda x : x.replace(\" \", \"\") , df.columns)\n",
    "labels = df['Label'] - 1\n",
    "#header = df.columns\n",
    "#df = preprocessing.scale(df.ix[:,df.columns.difference(['Label'])])\n",
    "header = list(set(df.columns) - set(['BetweenCentGlobal2', 'BetweenCentGlobal1', 'GlobalDegree2', 'IsMostRecent1', 'IsMostRecent2',\n",
    "                                     'GlobalDegree1', 'Label', 'CoAuthorCountUsedMacro1', 'CoAuthorCountUsedMacro2']))\n",
    "df = preprocessing.scale(df.ix[:, header])\n",
    "#header = ['GlobalCurExp1', 'GlobalCurExp2']\n",
    "#df = preprocessing.scale(df.ix[:, header])\n",
    "\n",
    "train_features = []\n",
    "train_labels = []\n",
    "test_features = []\n",
    "test_labels = []\n",
    "\n",
    "for index, features in enumerate(df):\n",
    "    my_rand = np.random.uniform(0, 1)\n",
    "    if my_rand <= 0.8:\n",
    "        train_features.append(features)\n",
    "        train_labels.append(labels[index])\n",
    "    else:\n",
    "        test_features.append(features)\n",
    "        test_labels.append(labels[index])\n",
    "\n",
    "logistic = LogisticRegression(C=1e5)\n",
    "logistic.fit(train_features, train_labels)\n",
    "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
    "            fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
    "        \n",
    "predictions = logistic.predict(test_features)\n",
    "five_decimals = [\"%.5f\" % v for v in logistic.coef_[0]]\n",
    "five_decimals = map(lambda x: float(x), five_decimals)\n",
    "five_decimals_intercept = [\"%.5f\" % logistic.intercept_]\n",
    "\n",
    "print ' Coefficients: ', sorted(zip(header, five_decimals), key=lambda x: -abs(x[1])), five_decimals_intercept\n",
    "print \"Accuracy: \",  accuracy_score(test_labels, predictions)\n",
    "print \"Majority: \", max(1 - sum(test_labels) / float(len(test_labels)), sum(test_labels) / float(len(test_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
