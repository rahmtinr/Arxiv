{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk \n",
    "import operator\n",
    "import math\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_POS = []\n",
    "f = open('/home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/Part Of Speech/POS.txt')\n",
    "for line in f:\n",
    "    global_POS.append(line[0:2])\n",
    "\n",
    "global_POS = list(set(global_POS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'heller.u.m'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-252-c2143dd93ea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpaper\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpapers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mauthor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mauthor_papers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mauthor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mauthor_experience\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mauthor_experience\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'heller.u.m'"
     ]
    }
   ],
   "source": [
    "class Paper:\n",
    "    def __init__(self, title):\n",
    "         self.title = title\n",
    "         self.authors = []\n",
    "         self.experiences = []\n",
    "         self.year = ''\n",
    "         self.pos = []\n",
    "         self.features = dict()\n",
    "         self.tag = \"\"\n",
    "         \n",
    "    def to_string(self):\n",
    "        return [self.title, self.year, self.authors, self.features]\n",
    "    \n",
    "\n",
    "f = open('/home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/Part Of Speech/TitlesAndAuthorsAndMonth4.txt')\n",
    "papers = []\n",
    "paper = Paper('test')\n",
    "counter = 0;\n",
    "global_features = [':', '?' , 'MATH']\n",
    "tag = \"\"\n",
    "author_papers = dict()\n",
    "\n",
    "for line in f:\n",
    "    try:\n",
    "        text = nltk.word_tokenize(line)\n",
    "    except UnicodeDecodeError:\n",
    "        for line2 in f:\n",
    "            if len(nltk.word_tokenize(line2)) == 0:\n",
    "                break\n",
    "        continue\n",
    "\n",
    "    if len(text) == 0:\n",
    "        papers.append(paper)\n",
    "        counter = counter + 1\n",
    "#        if counter >= 50:\n",
    "#            break\n",
    "        continue\n",
    "\n",
    "    if text[0] == 'Tag':\n",
    "        tag = text[2]\n",
    "        \n",
    "    if text[0] == 'Title':\n",
    "        title = (' '.join(text[2:])).lower().decode('utf-8', 'ignore').encode('utf-8', 'ignore')\n",
    "        number = 0\n",
    "        tmp = ''\n",
    "        for x in title:\n",
    "            if x == '$':\n",
    "                if number == 1:\n",
    "                    tmp = tmp + \" MATH \"\n",
    "                number = 1 - number\n",
    "                continue\n",
    "            if number > 0:\n",
    "                continue\n",
    "            tmp = tmp + x\n",
    "        paper = Paper(' '.join(tmp.split()))\n",
    "        paper.pos = nltk.pos_tag(nltk.word_tokenize(paper.title))\n",
    "        if len(paper.pos) > 0:\n",
    "            paper.pos[0] = (paper.pos[0][0], paper.pos[0][1][:2])\n",
    "        paper.tag = tag\n",
    "        for feature in global_features: \n",
    "            paper.features[feature] = 0\n",
    "            if feature in paper.title:\n",
    "                paper.features[feature] = 1\n",
    "            \n",
    "    \n",
    "    if text[0] == 'Year':\n",
    "        if text[2][0] == '9':\n",
    "            text[2] = '19' + text[2]\n",
    "        else:\n",
    "            text[2] = '20' + text[2]\n",
    "        paper.year = text[2]\n",
    "    if text[0] == 'Author':\n",
    "        author = ' '.join(text[2:]).lower()\n",
    "        paper.authors.append(' '.join(author.split()))\n",
    "    \n",
    "papers.sort(key=operator.attrgetter('year'))\n",
    "author_experience = dict()\n",
    "author_papers = dict()\n",
    "for index, paper in enumerate(papers):\n",
    "    for author in paper.authors:\n",
    "        if author not in author_experience:\n",
    "            author_experience[author] = 0\n",
    "            author_papers[author] = []\n",
    "        author_papers[author].append(index)\n",
    "        paper.experiences.append(author_experience[author])\n",
    "        author_experience[author] = author_experience[author] + 1\n",
    "\n",
    "#    print \"---->\", paper.authors, paper.year\n",
    "#    print paper.experiences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "def find_scores(paper_list):\n",
    "    if(len(paper_list) < min_for_min_threshold):\n",
    "        sys.exit()\n",
    "    ret = dict()\n",
    "    for feature in global_features:\n",
    "        ret[feature] = 0\n",
    "    for feature in global_POS:\n",
    "        ret[feature] = 0\n",
    "    for index in paper_list:\n",
    "        paper = papers[index]\n",
    "        for feature in global_features:\n",
    "            ret[feature] = ret[feature] + int(paper.features[feature])\n",
    "        for feature in global_POS:\n",
    "            if len(paper.pos) > 0:\n",
    "                ret[feature] = ret[feature] + int(paper.pos[0][1] == feature)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-326-29169c0b5a63>, line 56)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-326-29169c0b5a63>\"\u001b[0;36m, line \u001b[0;32m56\u001b[0m\n\u001b[0;31m    max(\"(paper.experiences),\", \"(float(younger_score)\", \"/\", \"len(younger_papers)))\")\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "author_papers = dict()\n",
    "\n",
    "fight_count = 0\n",
    "author_pairs = set()\n",
    "regression_scores = dict()\n",
    "regression_label = dict()\n",
    "denom = dict()\n",
    "num = dict()\n",
    "ratio = dict()\n",
    "first_pos_point = []\n",
    "\n",
    "min_for_min_threshold = 1\n",
    "max_for_min_threshold = 2\n",
    "\n",
    "for feature in global_features + global_POS:\n",
    "    denom[feature] = dict()\n",
    "    num[feature] = dict()\n",
    "    ratio[feature] = dict()\n",
    "    regression_scores[feature] = []\n",
    "    regression_label[feature] = []\n",
    "\n",
    "    \n",
    "for index, paper in enumerate(papers):\n",
    "    if len(paper.authors) == 2 and len(paper.pos) > 0:\n",
    "        if tuple(paper.authors) not in author_pairs:\n",
    "            older_index = younger_index = 0\n",
    "            if paper.experiences[0] < paper.experiences[1]: \n",
    "                older_index = 1\n",
    "            else:\n",
    "                younger_index = 1\n",
    "            \n",
    "            if(min(paper.experiences) >= min_for_min_threshold and min(paper.experiences) <= max_for_min_threshold and\n",
    "              paper.experiences[older_index] / paper.experiences[younger_index] > 2 and \n",
    "              paper.experiences[older_index] - paper.experiences[younger_index] > 10):\n",
    "               \n",
    "                # we found a fight\n",
    "                fight_count += 1\n",
    "                older_papers = author_papers[paper.authors[older_index]]\n",
    "                younger_papers = author_papers[paper.authors[younger_index]]\n",
    "                older_papers = list(set(older_papers) - set(younger_papers))\n",
    "                younger_papers = list(set(younger_papers) - set(older_papers))\n",
    "                older_scores = find_scores(older_papers)\n",
    "                younger_scores = find_scores(younger_papers)\n",
    "                for feature in global_features + global_POS:\n",
    "                    younger_score = younger_scores[feature]\n",
    "                    older_score = older_scores[feature]\n",
    "                    if (younger_score, older_score) not in denom[feature]:\n",
    "                        denom[feature][(younger_score, older_score)] = 0\n",
    "                        num[feature][(younger_score, older_score)] = 0\n",
    "                    denom[feature][(younger_score, older_score)] = denom[feature][(younger_score, older_score)] + 1\n",
    "                    regression_scores[feature].append([younger_score, older_score])\n",
    "                    \n",
    "                    my_tuple = (float(younger_score) / len(younger_papers), min(paper.experiences),\n",
    "                                (float(older_score) / len(older_papers)), max(paper.experiences))\n",
    "                   \n",
    "                    if my_tuple not in one_sided_regression_denom[feature]: \n",
    "                        one_sided_regression_denom[feature][my_tuple] = 0\n",
    "                        one_sided_regression_num[feature][my_tuple] = 0\n",
    "                    one_sided_regression_denom[feature][my_tuple] += 1    \n",
    "               \n",
    "                    if feature in global_features:\n",
    "                        regression_label[feature].append(paper.features[feature])\n",
    "                        if paper.features[feature] == 0:\n",
    "                            continue\n",
    "                        num[feature][(younger_score, older_score)] = num[feature][(younger_score, older_score)] + 1\n",
    "                        one_sided_regression_num[feature][my_tuple] += 1\n",
    "                    if feature in global_POS:\n",
    "                        regression_label[feature].append(int(paper.pos[0][1] == feature))\n",
    "                        num[feature][(younger_score, older_score)] = (num[feature][(younger_score, older_score)] +\n",
    "                                                                      int(paper.pos[0][1] == feature))\n",
    "                        one_sided_regression_num[feature][my_tuple] += int(paper.pos[0][1] == feature)\n",
    "                    \n",
    "                \n",
    "    for author1 in paper.authors:\n",
    "        for author2 in paper.authors:\n",
    "            author_pairs.add((author1, author2))\n",
    "            author_pairs.add((author2, author1))\n",
    "        if author1 not in author_papers:\n",
    "            author_papers[author1] = []\n",
    "        author1_papers = author_papers[author1]\n",
    "#        while len(author1_papers) >= min_for_min_threshold:\n",
    "#            author1_papers.pop(0)\n",
    "        author1_papers.append(index)\n",
    "        author_papers[author1] = author1_papers\n",
    "\n",
    "print fight_count\n",
    "\n",
    "for feature in global_features + global_POS:\n",
    "    copy1 = dict()\n",
    "    copy2 = dict()\n",
    "    for my_tuple in denom[feature]:\n",
    "        denom[feature][my_tuple] = max(1, denom[feature][my_tuple])\n",
    "        ratio[feature][my_tuple] =  (num[feature][my_tuple] / float(denom[feature][my_tuple]))\n",
    "        (i,j) = my_tuple\n",
    "        if ((j,i) not in denom[feature]):\n",
    "            copy1[(j, i)] = 1\n",
    "            copy2[(j, i)] = 0\n",
    "    denom[feature].update(copy1)\n",
    "    num[feature].update(copy2)\n",
    "    ratio[feature].update(copy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "relevant_features = ['VB', 'NN', 'RB', 'JJ', 'DT']\n",
    "for feature in relevant_features + global_features:\n",
    "    for (i,j) in num[feature]:\n",
    "        if i < j: # i is younger, j is older\n",
    "        #(younger less usage, older more usage) - (older less usage, younger more usage)\n",
    "                    \n",
    "            p_value = scipy.stats.binom_test(num[feature][(j,i)], denom[feature][(j,i)], ratio[feature][(i,j)], alternative='two-sided')\n",
    "               \n",
    "            mean1 = ratio[feature][(i,j)]\n",
    "            var1 = mean1 * (1 - mean1)\n",
    "                #print mean1, (1 - mean1), var1\n",
    "            mean2 = ratio[feature][(j,i)]\n",
    "            var2 = mean2 * (1 - mean2)\n",
    "                #print mean2, (1 - mean2), var2\n",
    "            sample_numbers = denom[feature][(i,j)] + denom[feature][(j,i)]\n",
    "            CI = 1.96  * (var1 + var2) / (math.sqrt(denom[feature][(i,j)]) + math.sqrt(denom[feature][(j,i)]))\n",
    "    \n",
    "        #print (feature, i, j,\n",
    "        #       str(ratio[feature][(i,j)] - ratio[feature][(j,i)]) + \" +/- \" + str(CI), p_value,\n",
    "        #       num[feature][(i,j)], denom[feature][(i,j)],\n",
    "        #       num[feature][(j,i)], denom[feature][(j,i)] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0737011853763\n",
      "VB  Coefficients:  [  7.07154756e-01   4.98917268e-04  -2.79026144e-02]\n",
      "0.167052754389\n",
      "NN  Coefficients:  [  5.19305877e-01   2.95127217e-04   2.33862861e-02]\n",
      "0.00546817581747\n",
      "RB  Coefficients:  [  1.11324930e-01   8.38558121e-05   8.07285672e-02]\n",
      "0.15809471992\n",
      "JJ  Coefficients:  [  3.37949270e-01   3.56943111e-05   6.00979938e-02]\n",
      "0.0864895609205\n",
      "DT  Coefficients:  [  4.87405781e-01  -7.51578775e-05   5.45177295e-02]\n",
      "0.0784952798784\n",
      ":  Coefficients:  [  7.75062864e-01  -1.96763652e-04   2.44365016e-02]\n",
      "0.0279744764055\n",
      "?  Coefficients:  [  4.47635552e-01  -9.00852820e-07   9.70271591e-02]\n",
      "0.108635251385\n",
      "MATH  Coefficients:  [  7.62328824e-01   2.36346496e-04   1.15434048e-01]\n"
     ]
    }
   ],
   "source": [
    "## One sided tuple experiment:\n",
    "from random import randrange\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def do_regression(data):\n",
    "    for feature in relevant_features + global_features:\n",
    "        one_sided_regression_features = [[], []]\n",
    "        one_sided_regression_labels = [[], []]\n",
    "        for key in data[feature]:\n",
    "            random_index = randrange(0,2)\n",
    "            one_sided_regression_features[random_index].append(list(key))\n",
    "            one_sided_regression_labels[random_index].append(data[feature][key])\n",
    "#    print one_sided_regression_features[0][0], one_sided_regression_features[1][0]\n",
    "#    print one_sided_regression_labels[0][0], one_sided_regression_labels[1][0]\n",
    "#    break\n",
    "        clf = linear_model.LinearRegression() # first one is younger, second one is older\n",
    "        clf.fit(one_sided_regression_features[0], one_sided_regression_labels[0])\n",
    "        prediction = clf.predict(one_sided_regression_features[1])\n",
    "        print mean_squared_error(one_sided_regression_labels[1], prediction)\n",
    "        print feature, ' Coefficients: ', clf.coef_\n",
    "        \n",
    "\n",
    "one_sided_regression_num = dict()\n",
    "one_sided_regression_denom = dict()\n",
    "one_sided_num_compact = dict()\n",
    "one_sided_denom_compact = dict()\n",
    "young_sided_regression_ratio = dict()\n",
    "old_sided_regression_ratio = dict()\n",
    "both_sided_regression_ratio = dict()\n",
    "\n",
    "for feature in global_features + global_POS:\n",
    "    one_sided_regression_num[feature] = dict()\n",
    "    one_sided_regression_denom[feature] = dict()\n",
    "    young_sided_regression_ratio[feature] = dict()\n",
    "    old_sided_regression_ratio[feature] = dict()\n",
    "    one_sided_num_compact[feature] = dict()\n",
    "    one_sided_denom_compact[feature] = dict()\n",
    "    both_sided_regression_ratio[feature] = dict()\n",
    "\n",
    "for feature in global_features + global_POS:\n",
    "    for my_tuple in one_sided_regression_num[feature]:\n",
    "        # (young_prob, young_exp, old_prob, old_exp)\n",
    "        both_sided_regression_ratio[feature] = (one_sided_num_compact[feature][my_tuple] / \n",
    "                                                   max(one_sided_denom_compact[feature][my_tuple], 1)\n",
    "\n",
    "        compact_tuple = (mytuple[0], my_tuple[1], my_tuple[3])\n",
    "        if comapct_tuple not in one_sided_num_compact[feature]:\n",
    "            one_sided_num_compact[feature][compact_tuple] = 0\n",
    "            one_sided_denom_compact[feature][compact_tuple] = 0\n",
    "        one_sided_num_compact[feature][compact_tuple] += one_sided_regression_num\n",
    "        one_sided_denom_compact[feature][compact_tuple] += one_sided_regression_denom\n",
    "    for my_tuple in one_sided_denom_compact:\n",
    "        young_sided_regression_ratio[feature] = (one_sided_num_compact[feature][compact_tuple] / \n",
    "                                                    max(one_sided_denom_compact[feature][compact_tuple], 1)\n",
    "\n",
    "for feature in global_features + global_POS:\n",
    "    one_sided_num_compact[feature] = dict()\n",
    "    one_sided_denom_compact[feature] = dict()\n",
    "    for my_tuple in one_sided_regression_num[feature]:\n",
    "        # (young_prob, young_exp, old_prob, old_exp)\n",
    "        compact_tuple = (mytuple[2], my_tuple[3], my_tuple[1])\n",
    "        if comapct_tuple not in one_sided_num_compact[feature]:\n",
    "            one_sided_num_compact[feature][compact_tuple] = 0\n",
    "            one_sided_denom_compact[feature][compact_tuple] = 0\n",
    "        one_sided_num_compact[feature][compact_tuple] += one_sided_regression_num\n",
    "        one_sided_denom_compact[feature][compact_tuple] += one_sided_regression_denom\n",
    "    for my_tuple in one_sided_denom_compact:\n",
    "        old_sided_regression_ratio[feature] = (one_sided_num_compact[feature][compact_tuple] / \n",
    "                                                    max(one_sided_denom_compact[feature][compact_tuple], 1)\n",
    "                                                 \n",
    "relevant_features = ['VB', 'NN', 'RB', 'JJ', 'DT']\n",
    "\n",
    "print \"OLD:\"\n",
    "do_regression(old_sided_regression_ratio)\n",
    "print \"YOUNG:\"                                               \n",
    "do_regression(young_sided_regression_ratio)\n",
    "print \"ALL:\"                      \n",
    "do_regression(both_sided_regression_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(': Coefficients: \\n', array([ 0.04995714,  0.09220335]))\n",
      "('? Coefficients: \\n', array([ 0.0498383 ,  0.07224182]))\n",
      "('MATH Coefficients: \\n', array([ 0.1229862 ,  0.14732743]))\n"
     ]
    }
   ],
   "source": [
    "# from sklearn import linear_model\n",
    "clf = linear_model.LinearRegression() # first one is younger, second one is older\n",
    "#print regression_scores[':']\n",
    "clf.fit(regression_scores[':'], regression_label[':'])\n",
    "print(': Coefficients: \\n', clf.coef_)\n",
    "clf.fit(regression_scores['?'], regression_label['?'])\n",
    "print('? Coefficients: \\n', clf.coef_)\n",
    "clf.fit(regression_scores['MATH'], regression_label['MATH'])\n",
    "print('MATH Coefficients: \\n', clf.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "younger, older wins:  781 761\n"
     ]
    }
   ],
   "source": [
    "\n",
    "older_wins_count = 0                                                                           \n",
    "younger_wins_count = 0\n",
    "for x in first_pos_point:\n",
    "    if x[0] < x[1]:\n",
    "        older_wins_count += 1\n",
    "    elif x[1] < x[0]:\n",
    "        younger_wins_count += 1\n",
    "\n",
    "print \"younger, older wins: \", younger_wins, older_wins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
