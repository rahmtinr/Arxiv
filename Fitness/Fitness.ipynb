{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os \n",
    "from random import shuffle\n",
    "import sys\n",
    "randBinList = lambda n: [randint(0,1) for b in range(1,n+1)]\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k All NoSpeed OnlySpeed SpeedAndExperience\n",
      "10 0.740777777778 0.696888888889 0.716390728477 0.641887417219 0.681903916565 0.649173416177 0.713930348259 0.674350469873\n",
      "20 0.771661456007 0.743412237606 0.742260414295 0.673628499886 0.712492836676 0.695759312321 0.743757838331 0.719587276251\n",
      "30 0.807664233577 0.780778588808 0.75583515682 0.687879893022 0.728971401106 0.715633261235 0.765049858427 0.747507078666\n",
      "40 0.82565528197 0.775681758009 0.777142857143 0.672890365449 0.741783100466 0.714238190286 0.779684237996 0.731667536534\n",
      "50 0.836362303972 0.788362890224 0.797370740306 0.667082843713 0.760559319591 0.730070635721 0.794495810459 0.761918520659\n",
      "60 0.842797561758 0.778152069297 0.80137987013 0.667938311688 0.761808148028 0.721717253693 0.806951697128 0.763789164491\n",
      "70 0.833765272121 0.781192151055 0.795140152894 0.66427011285 0.77020573108 0.710966201323 0.813579349209 0.748500272678\n",
      "80 0.84387755102 0.780714285714 0.799496981891 0.674144869215 0.782261326861 0.715716019417 0.81881390593 0.768302658487\n",
      "90 0.856219709208 0.817101315486 0.812295081967 0.688641686183 0.794298745724 0.747092360319 0.820249365043 0.807550219349\n",
      "100 0.850207146556 0.852796478509 0.805283505155 0.728865979381 0.793383110196 0.76377445932 0.827393340271 0.827913631634\n",
      "110 0.850329418505 0.851618447436 0.81231884058 0.717971014493 0.790911747516 0.764757451783 0.824258836944 0.837371721779\n",
      "120 0.849068519103 0.854278497 0.805998125586 0.710871602624 0.801883878938 0.766059295862 0.833941605839 0.825425790754\n",
      "130 0.853531971878 0.851858051557 0.796474891919 0.711007648819 0.797854508884 0.773550117332 0.833941605839 0.825812873258\n",
      "140 0.844982078853 0.846594982079 0.802583697234 0.699599708879 0.787862318841 0.743115942029 0.831093031482 0.813052706049\n",
      "150 0.837514039686 0.83077499064 0.813461538462 0.702884615385 0.805107526882 0.742703533026 0.839463601533 0.811685823755\n",
      "160 0.855429036194 0.824928832859 0.814123376623 0.700487012987 0.791398713826 0.728697749196 0.830684596577 0.790138549307\n",
      "170 0.853411053541 0.820595854922 0.805073720729 0.696444058977 0.805947136564 0.723568281938 0.836525903352 0.789508053983\n",
      "180 0.849637681159 0.801856884058 0.799210872424 0.684129767646 0.793458781362 0.724910394265 0.830885625278 0.787494437027\n",
      "190 0.852455146364 0.82672332389 0.802912621359 0.688106796117 0.794540229885 0.722461685824 0.845260663507 0.767298578199\n",
      "200 0.843257874016 0.814960629921 0.800737100737 0.710073710074 0.802770780856 0.724937027708 0.838155958803 0.761893084846\n"
     ]
    }
   ],
   "source": [
    "######## Macro fitness \n",
    "\n",
    "def do_prediction(points, header, text):\n",
    "    points_features = [[],[]]\n",
    "    points_labels = [[],[]]\n",
    "    train_features = []\n",
    "    test_features = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "    \n",
    "    shuffle(points[0])\n",
    "    shuffle(points[1])\n",
    "        \n",
    "    bound = min(len(points[0]), len(points[1]))\n",
    "    points[0] = points[0][:bound]\n",
    "    points[1] = points[1][:bound]\n",
    "    for i in range(len(points)):\n",
    "        all_labels = map(lambda x: int(x[-1]) , points[0] + points[1])\n",
    "        all_features = map(lambda x: x[:-1], points[0] + points[1])\n",
    "    points = []\n",
    "    all_features = preprocessing.scale(all_features)\n",
    "    \n",
    "    for i in range(len(all_features)):\n",
    "        points_features[all_labels[i]].append(all_features[i])\n",
    "        \n",
    "    split_points = np.random.randint(2, size=len(points_features[0]))\n",
    "    for i in range(len(split_points)):\n",
    "        if(split_points[i] == 0):\n",
    "            train_features.append(points_features[0][i])\n",
    "            train_features.append(points_features[1][i])\n",
    "            train_labels.append(0)\n",
    "            train_labels.append(1)\n",
    "        else:\n",
    "            test_features.append(points_features[0][i])\n",
    "            test_features.append(points_features[1][i])\n",
    "            test_labels.append(0)\n",
    "            test_labels.append(1)\n",
    "\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(train_features, train_labels)\n",
    "    predictions = clf.predict(test_features)\n",
    "    print accuracy_score(test_labels, predictions),\n",
    "    logistic = LogisticRegression(C=1e5)\n",
    "    logistic.fit(train_features, train_labels)\n",
    "    LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
    "    fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "        multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "        solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "    predictions = logistic.predict(test_features) \n",
    "    temp = [\"%.5f\" % v for v in logistic.coef_[0]]\n",
    "    five_decimals = [float(i) for i in temp]\n",
    "    five_decimals_intercept = [\"%.5f\" % logistic.intercept_]\n",
    "    five_decimals = sorted(zip(header, five_decimals), key=lambda x: -abs(x[1]))\n",
    "#    print \"Coefficients: \",(five_decimals, five_decimals_intercept)\n",
    "    \n",
    "    print accuracy_score(test_labels, predictions),\n",
    "    \n",
    "print \"k All NoSpeed OnlySpeed SpeedAndExperience\"    \n",
    "for k in range(10,201,10):\n",
    "    print k,\n",
    "    df = pd.read_csv('/home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/RawOutput/Name/PredictionFiles/k_2k_prediction_' + str(k) + '.txt')\n",
    "    df.columns = map(lambda x : x.replace(\" \", \"\") , df.columns)\n",
    "    my_copy = df.copy()\n",
    "    header = df.columns.tolist()\n",
    "\n",
    "    temp = map(list, df.values)\n",
    "    points = [[],[]]\n",
    "    for i in range(len(temp)):\n",
    "        points[int(temp[i][-1])].append(temp[i])\n",
    "    do_prediction(points, header, \"              \")\n",
    "    \n",
    "    \n",
    "    ############################################ remove all speed\n",
    "    del df['NumberOfPapers']\n",
    "    del df['HalfSpeed']\n",
    "    del df['FullSpeed']\n",
    "    header = df.columns.tolist()\n",
    "    temp = map(list, df.values)\n",
    "    points = [[],[]]\n",
    "    for i in range(len(temp)):\n",
    "        points[int(temp[i][-1])].append(temp[i])\n",
    "    do_prediction(points, header, \" Without speed features\")\n",
    "    ############################################ only speed features\n",
    "    df = my_copy[['NumberOfPapers', 'HalfSpeed', 'FullSpeed', 'Label']]\n",
    "    header = df.columns.tolist()\n",
    "    temp = map(list, df.values)\n",
    "    points = [[],[]]\n",
    "    for i in range(len(temp)):\n",
    "        points[int(temp[i][-1])].append(temp[i])\n",
    "    do_prediction(points, header, \" All speed features\")\n",
    "    ########################################## exp and speed\n",
    "    df = my_copy[['NumberOfPapers', 'HalfSpeed', 'FullSpeed', 'AvgUsingExp', \n",
    "                  'HalfAvgUsingExp', 'AvgAdoptionExp', 'HalfAvgAdoptionExp', 'Label']]\n",
    "    header = df.columns.tolist()\n",
    "    temp = map(list, df.values)\n",
    "    points = [[],[]]\n",
    "    for i in range(len(temp)):\n",
    "        points[int(temp[i][-1])].append(temp[i])\n",
    "    do_prediction(points, header, \" Speed and Experience\")\n",
    "    ######################################33\n",
    "#    df = my_copy[['AvgUsingExp', 'HalfAvgUsingExp', 'AvgAdoptionExp', 'HalfAvgAdoptionExp', 'Label']]\n",
    "#    header = df.columns.tolist()\n",
    "#    temp = map(list, df.values)\n",
    "#    points = [[],[]]\n",
    "#    for i in range(len(temp)):\n",
    "#        points[int(temp[i][-1])].append(temp[i])\n",
    "#    do_prediction(points, header, \" Speed and Experience\")\n",
    "    \n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53557312253\n"
     ]
    }
   ],
   "source": [
    "######## author fitness \n",
    "df = pd.read_csv('/home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/RawOutput/author_35_dies_before_45_or_reaches_55.txt')\n",
    "df.columns = map(lambda x : x.replace(\" \", \"\") , df.columns)\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "x= df[0:1]['ChangeFractionHighUsage']\n",
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= 0.75\n",
    "#median = np.median(df['FinalGlobalExp'].tolist())\n",
    "#print \"median: \",median\n",
    "#df['Label'] = np.where(df['FinalGlobalExp'] > median, 1, 0)\n",
    "\n",
    "train = df[df['is_train'] == True]\n",
    "test = df[df['is_train'] == False]\n",
    "#train_features = train.ix[:, df.columns.difference(['Label', 'is_train', 'FinalGlobalExp'])]\n",
    "train_features = train.ix[:, df.columns.difference(['Label', 'is_train'])]\n",
    "train_labels = train['Label']\n",
    "#test_features = test.ix[:, df.columns.difference(['Label', 'is_train','FinalGlobalExp'])]\n",
    "test_features = test.ix[:, df.columns.difference(['Label', 'is_train'])]\n",
    "test_labels = test['Label']\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(test_features)\n",
    "print accuracy_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
