{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os \n",
    "from random import shuffle\n",
    "import sys\n",
    "randBinList = lambda n: [randint(0,1) for b in range(1,n+1)]\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k All NoSpeed OnlySpeed SpeedAndExperience\n",
      "10 0.735168563923 0.720495867769 0.672432911954 0.711615044248\n",
      "20 0.782208237986 0.739993177166 0.713782124176 0.744223289865\n",
      "30 0.808012741975 0.762751065125 0.731294145816 0.761557030779\n",
      "40 0.818710014362 0.780635003936 0.740726176432 0.782024387046\n",
      "50 0.83559247923 0.793336205658 0.759648868253 0.801925320887\n",
      "60 0.842934073107 0.796244897959 0.770008084074 0.811154598826\n",
      "70 0.848235952959 0.807755474453 0.772835438404 0.814316860465\n",
      "80 0.8400243309 0.806188268494 0.771829839202 0.810483870968\n",
      "90 0.857044830741 0.811338076658 0.796997690531 0.825255972696\n",
      "100 0.863163371488 0.802322580645 0.793638676845 0.827894736842\n",
      "110 0.852024922118 0.800892600058 0.787176570941 0.825311438279\n",
      "120 0.853083434099 0.807585139319 0.804497189257 0.841376089664\n",
      "130 0.850527749404 0.813484251969 0.793521594684 0.835175879397\n",
      "140 0.861131123919 0.811290322581 0.789398280802 0.834704830054\n",
      "150 0.856193009119 0.790976058932 0.795998504114 0.83249516441\n",
      "160 0.843232323232 0.804232804233 0.806346623271 0.842868654311\n",
      "170 0.845125107852 0.80151187905 0.793302047782 0.837974683544\n",
      "180 0.86202247191 0.806912442396 0.797479747975 0.827538247566\n",
      "190 0.855755566082 0.802489431658 0.805620608899 0.843794242567\n",
      "200 0.84725 0.798271604938 0.809845077461 0.84081934847\n"
     ]
    }
   ],
   "source": [
    "######## Macro fitness \n",
    "\n",
    "def do_prediction(points, header, text):\n",
    "    points_features = [[],[]]\n",
    "    points_labels = [[],[]]\n",
    "    train_features = []\n",
    "    test_features = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "    \n",
    "    shuffle(points[0])\n",
    "    shuffle(points[1])\n",
    "        \n",
    "    bound = min(len(points[0]), len(points[1]))\n",
    "    points[0] = points[0][:bound]\n",
    "    points[1] = points[1][:bound]\n",
    "    for i in range(len(points)):\n",
    "        all_labels = map(lambda x: int(x[-1]) , points[0] + points[1])\n",
    "        all_features = map(lambda x: x[:-1], points[0] + points[1])\n",
    "    points = []\n",
    "    all_features = preprocessing.scale(all_features)\n",
    "    \n",
    "    for i in range(len(all_features)):\n",
    "        points_features[all_labels[i]].append(all_features[i])\n",
    "        \n",
    "    split_points = np.random.randint(2, size=len(points_features[0]))\n",
    "    for i in range(len(split_points)):\n",
    "        if(split_points[i] == 0):\n",
    "            train_features.append(points_features[0][i])\n",
    "            train_features.append(points_features[1][i])\n",
    "            train_labels.append(0)\n",
    "            train_labels.append(1)\n",
    "        else:\n",
    "            test_features.append(points_features[0][i])\n",
    "            test_features.append(points_features[1][i])\n",
    "            test_labels.append(0)\n",
    "            test_labels.append(1)\n",
    "\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(train_features, train_labels)\n",
    "    predictions = clf.predict(test_features)\n",
    "    print accuracy_score(test_labels, predictions),\n",
    "    logistic = LogisticRegression(C=1e5)\n",
    "    logistic.fit(train_features, train_labels)\n",
    "    LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
    "    fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "        multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "        solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "    predictions = logistic.predict(test_features) \n",
    "    temp = [\"%.5f\" % v for v in logistic.coef_[0]]\n",
    "    five_decimals = [float(i) for i in temp]\n",
    "    five_decimals_intercept = [\"%.5f\" % logistic.intercept_]\n",
    "    five_decimals = sorted(zip(header, five_decimals), key=lambda x: -abs(x[1]))\n",
    "#    print \"Coefficients: \",(five_decimals, five_decimals_intercept)\n",
    "    \n",
    "#    print accuracy_score(test_labels, predictions),\n",
    "    \n",
    "print \"k All NoSpeed OnlySpeed SpeedAndExperience\"    \n",
    "for k in range(10,201,10):\n",
    "    print k,\n",
    "    df = pd.read_csv('/home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/RawOutput/Name/PredictionFiles/k_2k_prediction_' + str(k) + '.txt')\n",
    "    df.columns = map(lambda x : x.replace(\" \", \"\") , df.columns)\n",
    "    my_copy = df.copy()\n",
    "    header = df.columns.tolist()\n",
    "\n",
    "    temp = map(list, df.values)\n",
    "    points = [[],[]]\n",
    "    for i in range(len(temp)):\n",
    "        points[int(temp[i][-1])].append(temp[i])\n",
    "    do_prediction(points, header, \"              \")\n",
    "    \n",
    "    \n",
    "    ############################################ remove all speed\n",
    "    del df['NumberOfPapers']\n",
    "    del df['HalfSpeed']\n",
    "    del df['FullSpeed']\n",
    "    header = df.columns.tolist()\n",
    "    temp = map(list, df.values)\n",
    "    points = [[],[]]\n",
    "    for i in range(len(temp)):\n",
    "        points[int(temp[i][-1])].append(temp[i])\n",
    "    do_prediction(points, header, \" Without speed features\")\n",
    "    ############################################ only speed features\n",
    "    df = my_copy[['NumberOfPapers', 'HalfSpeed', 'FullSpeed', 'Label']]\n",
    "    header = df.columns.tolist()\n",
    "    temp = map(list, df.values)\n",
    "    points = [[],[]]\n",
    "    for i in range(len(temp)):\n",
    "        points[int(temp[i][-1])].append(temp[i])\n",
    "    do_prediction(points, header, \" All speed features\")\n",
    "    ########################################## exp and speed\n",
    "    df = my_copy[['NumberOfPapers', 'HalfSpeed', 'FullSpeed', 'AvgUsingExp', \n",
    "                  'HalfAvgUsingExp', 'AvgAdoptionExp', 'HalfAvgAdoptionExp', 'Label']]\n",
    "    header = df.columns.tolist()\n",
    "    temp = map(list, df.values)\n",
    "    points = [[],[]]\n",
    "    for i in range(len(temp)):\n",
    "        points[int(temp[i][-1])].append(temp[i])\n",
    "    do_prediction(points, header, \" Speed and Experience\")\n",
    "    ######################################33\n",
    "#    df = my_copy[['AvgUsingExp', 'HalfAvgUsingExp', 'AvgAdoptionExp', 'HalfAvgAdoptionExp', 'Label']]\n",
    "#    header = df.columns.tolist()\n",
    "#    temp = map(list, df.values)\n",
    "#    points = [[],[]]\n",
    "#    for i in range(len(temp)):\n",
    "#        points[int(temp[i][-1])].append(temp[i])\n",
    "#    do_prediction(points, header, \" Speed and Experience\")\n",
    "    \n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.534368070953\n"
     ]
    }
   ],
   "source": [
    "######## author fitness \n",
    "df = pd.read_csv('/home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/RawOutput/author_35_dies_before_45_or_reaches_55.txt')\n",
    "df.columns = map(lambda x : x.replace(\" \", \"\") , df.columns)\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "x= df[0:1]['ChangeFractionHighUsage']\n",
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= 0.75\n",
    "#median = np.median(df['FinalGlobalExp'].tolist())\n",
    "#print \"median: \",median\n",
    "#df['Label'] = np.where(df['FinalGlobalExp'] > median, 1, 0)\n",
    "\n",
    "train = df[df['is_train'] == True]\n",
    "test = df[df['is_train'] == False]\n",
    "#train_features = train.ix[:, df.columns.difference(['Label', 'is_train', 'FinalGlobalExp'])]\n",
    "train_features = train.ix[:, df.columns.difference(['Label', 'is_train'])]\n",
    "train_labels = train['Label']\n",
    "#test_features = test.ix[:, df.columns.difference(['Label', 'is_train','FinalGlobalExp'])]\n",
    "test_features = test.ix[:, df.columns.difference(['Label', 'is_train'])]\n",
    "test_labels = test['Label']\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(test_features)\n",
    "print accuracy_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
