{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os \n",
    "from random import shuffle\n",
    "import sys\n",
    "randBinList = lambda n: [randint(0,1) for b in range(1,n+1)]\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k All NoSpeed OnlySpeed SpeedAndExperience\n",
      "10 73.7299465241 72.2203672788 67.9389312977 71.0573177518\n",
      "20 77.2393538913 74.4255462942 70.7826877201 75.1671009403\n",
      "30 80.7401631478 76.26547371 73.1641468683 76.015719468\n",
      "40 82.5995807128 77.4406332454 74.7646824871 77.9373024236\n",
      "50 83.8243959929 79.564586357 76.2238784159 79.958586008\n",
      "60 83.6685902721 80.1074406671 76.5454248899 80.7926341073\n",
      "70 84.1721371262 80.1639948406 76.8201674554 80.6457530728\n",
      "80 84.5907544527 80.422304223 78.1319796954 81.4222490445\n",
      "90 85.6708030906 80.6807935077 79.093799682 82.3772372648\n",
      "100 86.5693238621 80.889296957 78.6720584399 83.0805439331\n",
      "110 85.2603583427 81.0329985653 79.2395982783 82.9681565878\n",
      "120 84.5327102804 81.0764430577 79.3788819876 83.7128111718\n",
      "130 85.504556193 80.4106361494 79.112662014 83.1709774941\n",
      "140 85.3448275862 80.3126097647 79.6164772727 83.4415584416\n",
      "150 85.63525372 80.2369311771 80.0076016724 83.8066001535\n",
      "160 85.4406919275 80.4748260336 81.1074918567 83.7843215281\n",
      "170 86.0017308524 80.3501094092 78.9563729683 84.4850065189\n",
      "180 85.5867916109 81.3255709807 79.535198556 83.3029612756\n",
      "190 85.6899902818 79.5631067961 81.0531264692 83.1758034026\n",
      "200 85.2003862868 80.2870090634 79.7733847637 83.7394331179\n"
     ]
    }
   ],
   "source": [
    "######## Macro fitness \n",
    "\n",
    "def do_prediction(points, header, text):\n",
    "    points_features = [[],[]]\n",
    "    points_labels = [[],[]]\n",
    "    train_features = []\n",
    "    test_features = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "    \n",
    "    shuffle(points[0])\n",
    "    shuffle(points[1])\n",
    "        \n",
    "    bound = min(len(points[0]), len(points[1]))\n",
    "    points[0] = points[0][:bound]\n",
    "    points[1] = points[1][:bound]\n",
    "    for i in range(len(points)):\n",
    "        all_labels = map(lambda x: int(x[-1]) , points[0] + points[1])\n",
    "        all_features = map(lambda x: x[:-1], points[0] + points[1])\n",
    "    points = []\n",
    "    all_features = preprocessing.scale(all_features)\n",
    "    \n",
    "    for i in range(len(all_features)):\n",
    "        points_features[all_labels[i]].append(all_features[i])\n",
    "        \n",
    "    split_points = np.random.randint(2, size=len(points_features[0]))\n",
    "    for i in range(len(split_points)):\n",
    "        if(split_points[i] == 0):\n",
    "            train_features.append(points_features[0][i])\n",
    "            train_features.append(points_features[1][i])\n",
    "            train_labels.append(0)\n",
    "            train_labels.append(1)\n",
    "        else:\n",
    "            test_features.append(points_features[0][i])\n",
    "            test_features.append(points_features[1][i])\n",
    "            test_labels.append(0)\n",
    "            test_labels.append(1)\n",
    "\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(train_features, train_labels)\n",
    "    predictions = clf.predict(test_features)\n",
    "    print accuracy_score(test_labels, predictions)*100,\n",
    "    logistic = LogisticRegression(C=1e5)\n",
    "    logistic.fit(train_features, train_labels)\n",
    "    LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
    "    fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "        multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "        solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "    predictions = logistic.predict(test_features) \n",
    "    temp = [\"%.5f\" % v for v in logistic.coef_[0]]\n",
    "    five_decimals = [float(i) for i in temp]\n",
    "    five_decimals_intercept = [\"%.5f\" % logistic.intercept_]\n",
    "    five_decimals = sorted(zip(header, five_decimals), key=lambda x: -abs(x[1]))\n",
    "#    print \"Coefficients: \",(five_decimals, five_decimals_intercept)\n",
    "    \n",
    "#    print accuracy_score(test_labels, predictions),\n",
    "    \n",
    "print \"k All NoSpeed OnlySpeed SpeedAndExperience\"    \n",
    "for k in range(10,201,10):\n",
    "    print k,\n",
    "    df = pd.read_csv('/home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/RawOutput/Name/PredictionFiles/k_2k_prediction_' + str(k) + '.txt')\n",
    "    df.columns = map(lambda x : x.replace(\" \", \"\") , df.columns)\n",
    "    my_copy = df.copy()\n",
    "    header = df.columns.tolist()\n",
    "\n",
    "    temp = map(list, df.values)\n",
    "    points = [[],[]]\n",
    "    for i in range(len(temp)):\n",
    "        points[int(temp[i][-1])].append(temp[i])\n",
    "    do_prediction(points, header, \"              \")\n",
    "    \n",
    "    \n",
    "    ############################################ remove all speed\n",
    "    del df['NumberOfPapers']\n",
    "    del df['HalfSpeed']\n",
    "    del df['FullSpeed']\n",
    "    header = df.columns.tolist()\n",
    "    temp = map(list, df.values)\n",
    "    points = [[],[]]\n",
    "    for i in range(len(temp)):\n",
    "        points[int(temp[i][-1])].append(temp[i])\n",
    "    do_prediction(points, header, \" Without speed features\")\n",
    "    ############################################ only speed features\n",
    "    df = my_copy[['NumberOfPapers', 'HalfSpeed', 'FullSpeed', 'Label']]\n",
    "    header = df.columns.tolist()\n",
    "    temp = map(list, df.values)\n",
    "    points = [[],[]]\n",
    "    for i in range(len(temp)):\n",
    "        points[int(temp[i][-1])].append(temp[i])\n",
    "    do_prediction(points, header, \" All speed features\")\n",
    "    ########################################## exp and speed\n",
    "    df = my_copy[['NumberOfPapers', 'HalfSpeed', 'FullSpeed', 'AvgUsingExp', \n",
    "                  'HalfAvgUsingExp', 'AvgAdoptionExp', 'HalfAvgAdoptionExp', 'Label']]\n",
    "    header = df.columns.tolist()\n",
    "    temp = map(list, df.values)\n",
    "    points = [[],[]]\n",
    "    for i in range(len(temp)):\n",
    "        points[int(temp[i][-1])].append(temp[i])\n",
    "    do_prediction(points, header, \" Speed and Experience\")\n",
    "    ######################################33\n",
    "#    df = my_copy[['AvgUsingExp', 'HalfAvgUsingExp', 'AvgAdoptionExp', 'HalfAvgAdoptionExp', 'Label']]\n",
    "#    header = df.columns.tolist()\n",
    "#    temp = map(list, df.values)\n",
    "#    points = [[],[]]\n",
    "#    for i in range(len(temp)):\n",
    "#        points[int(temp[i][-1])].append(temp[i])\n",
    "#    do_prediction(points, header, \" Speed and Experience\")\n",
    "    \n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File /home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/RawOutput/author_35_dies_before_45_or_reaches_55.txt does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-262-6a2b25709517>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m######## author fitness\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/RawOutput/author_35_dies_before_45_or_reaches_55.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    496\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3246)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6111)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File /home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/RawOutput/author_35_dies_before_45_or_reaches_55.txt does not exist"
     ]
    }
   ],
   "source": [
    "######## author fitness \n",
    "df = pd.read_csv('/home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/RawOutput/author_35_dies_before_45_or_reaches_55.txt')\n",
    "df.columns = map(lambda x : x.replace(\" \", \"\") , df.columns)\n",
    "df.fillna(0, inplace=True)\n",
    "x= df[0:1]['ChangeFractionHighUsage']\n",
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= 0.75\n",
    "#median = np.median(df['FinalGlobalExp'].tolist())\n",
    "#print \"median: \",median\n",
    "#df['Label'] = np.where(df['FinalGlobalExp'] > median, 1, 0)\n",
    "\n",
    "train = df[df['is_train'] == True]\n",
    "test = df[df['is_train'] == False]\n",
    "#train_features = train.ix[:, df.columns.difference(['Label', 'is_train', 'FinalGlobalExp'])]\n",
    "train_features = train.ix[:, df.columns.difference(['Label', 'is_train'])]\n",
    "train_labels = train['Label']\n",
    "#test_features = test.ix[:, df.columns.difference(['Label', 'is_train','FinalGlobalExp'])]\n",
    "test_features = test.ix[:, df.columns.difference(['Label', 'is_train'])]\n",
    "test_labels = test['Label']\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(test_features)\n",
    "print accuracy_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-364-82250dc9698f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mpredictions1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mpredictions2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_features2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0macc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0macc2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 10"
     ]
    }
   ],
   "source": [
    "## author fitness \n",
    "import math\n",
    "lower_bound = dict()\n",
    "upper_bound = dict()\n",
    "acc1 = dict()\n",
    "acc2 = dict()\n",
    "num = 100\n",
    "test_size = dict()\n",
    "for j in range(0,num):\n",
    "    for i in range(10,51,10):\n",
    "        if j == 0:\n",
    "            acc1[i] = 0\n",
    "            acc2[i] = 0\n",
    "            test_size[i] = 0\n",
    "        ### read input \n",
    "        filename = '/home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/RawOutput/Name/author_fitness_' + str(i) + '.txt' \n",
    "        df = pd.read_csv(filename)\n",
    "        df.dropna()\n",
    "        df.columns = map(lambda x : x.replace(\" \", \"\") , df.columns)\n",
    "        df.fillna(0, inplace=True)\n",
    "        df['is_train'] = np.random.uniform(0, 1, len(df)) <= 0.75\n",
    "        median = np.median(df['FinalGlobalExp'].tolist())\n",
    "    #    print \"median: \",median\n",
    "        # separate the label = 1 from 0 and remove stuff between to make prediction easier\n",
    "        lower = .2\n",
    "        upper = .8\n",
    "        bounds = df.quantile([lower, upper])['FinalGlobalExp']\n",
    "        lower_bound[i] = bounds[lower]\n",
    "        upper_bound[i] = bounds[upper]\n",
    "    #    print \"bounds: \", bounds\n",
    "        df['Label'] = np.where(df['FinalGlobalExp'] >= lower_bound[i], 2, 0)\n",
    "        df['Label'] = np.where(np.logical_and(df['FinalGlobalExp'] >= upper_bound[i], df['Label'] == 2), 1, df['Label'])\n",
    "        df = df[df.Label != 2]\n",
    "    #    print df\n",
    "\n",
    "        ###\n",
    "        train = df[df['is_train'] == True]\n",
    "        test = df[df['is_train'] == False]\n",
    "    #    train_features = train.ix[:, df.columns.difference(['Label', 'is_train', 'FinalGlobalExp'])]\n",
    "        train_features2 = train[['ChangeFractionHighUsage']]\n",
    "        train_features1 = train[['CoAuthorCount']]\n",
    "\n",
    "        train_labels = train['Label']\n",
    "    #    test_features = test.ix[:, df.columns.difference(['Label', 'is_train','FinalGlobalExp'])]\n",
    "        test_features2 = test[['ChangeFractionHighUsage']]\n",
    "        test_features1 = test[['CoAuthorCount']]\n",
    "\n",
    "        test_labels = test['Label']\n",
    "        test_size[i] = test_size[i] + len(test)\n",
    "\n",
    "\n",
    "        logistic = LogisticRegression(C=1e5)\n",
    "        logistic.fit(train_features1, train_labels)\n",
    "        LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
    "        fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "            multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "            solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
    "    \n",
    "        clf = DecisionTreeClassifier()\n",
    "        clf = clf.fit(train_features2, train_labels)\n",
    "\n",
    "        predictions1 = logistic.predict(test_features1)\n",
    "        predictions2 = clf.predict(test_features2)\n",
    "        acc1[i] = acc1[i] + accuracy_score(test_labels, predictions1)\n",
    "        acc2[i] = acc2[i] + accuracy_score(test_labels, predictions2)\n",
    "\n",
    "print \"PapersRevealed 20Percentile 80Percentile CoAuthorCount ChangeFraction  deltay\"\n",
    "for i in range(10,51,10):\n",
    "    print i, lower_bound[i], upper_bound[i], acc1[i]/num, acc2[i]/num, 1/math.sqrt(test_size[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
