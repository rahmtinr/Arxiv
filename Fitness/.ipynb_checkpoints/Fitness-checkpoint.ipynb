{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os \n",
    "from random import shuffle\n",
    "import sys\n",
    "randBinList = lambda n: [randint(0,1) for b in range(1,n+1)]\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k All NoSpeed OnlySpeed SpeedAndExperience\n",
      "10 0.744836775483 0.695480790584 0.72049071618 0.641965075155 0.677850488021 0.650732031943 0.709082833666 0.672884743504\n",
      "20 0.775615567911 0.750652445251 0.738410971325 0.67675393857 0.713889831467 0.697206198394 0.743639475185 0.718710781517\n",
      "30 0.81056763285 0.785265700483 0.754811161896 0.682282896319 0.729956532239 0.723194880464 0.769893502453 0.740816082326\n",
      "40 0.815388655462 0.778230042017 0.778077327722 0.674842188322 0.74322169059 0.715045188729 0.776532630191 0.728345418589\n",
      "50 0.838750184665 0.787413207268 0.795567583382 0.668153891164 0.758474576271 0.723772647575 0.799563318777 0.760989810771\n",
      "60 0.840415180019 0.783571196886 0.8050997426 0.666827541828 0.769418661456 0.720648102915 0.805928594825 0.768997707173\n",
      "70 0.840694006309 0.783076637595 0.804189435337 0.676684881603 0.769090909091 0.713090909091 0.819129140305 0.752046892445\n",
      "80 0.846618852459 0.787090163934 0.80909829407 0.674451665313 0.773420036578 0.714692135745 0.813666528411 0.767938614683\n",
      "90 0.859724813433 0.822877798507 0.79904473439 0.687325256291 0.783165599268 0.745082342177 0.823082319925 0.790692235734\n",
      "100 0.853589012698 0.849831562581 0.814289466772 0.721171526136 0.792610710608 0.763516992791 0.833725798012 0.832286760858\n",
      "110 0.853634013215 0.849755817294 0.809865339578 0.726141686183 0.794375353307 0.763849632561 0.825271181472 0.831720902961\n",
      "120 0.859729895641 0.852670349908 0.801785164666 0.703293321022 0.802318392581 0.768469860896 0.820751833741 0.823349633252\n",
      "130 0.847956131605 0.843635759389 0.81704851752 0.71647574124 0.796681193429 0.765839758632 0.833557498319 0.818594485541\n",
      "140 0.857699115044 0.833097345133 0.818740955137 0.709479015919 0.798813376483 0.752606975908 0.835533357117 0.814484480913\n",
      "150 0.848120300752 0.836654135338 0.800946969697 0.698484848485 0.805975794251 0.749810892587 0.832314744079 0.807868601986\n",
      "160 0.851926977688 0.824137931034 0.813921021141 0.696848823295 0.804383788255 0.722497932175 0.8464 0.7984\n",
      "170 0.852351916376 0.820557491289 0.814568113451 0.692522561238 0.80561508787 0.730175739391 0.832476435304 0.77442159383\n",
      "180 0.845591493132 0.818342933097 0.802277904328 0.694077448747 0.799509366637 0.723907225691 0.841609195402 0.784827586207\n",
      "190 0.851763584366 0.816491897045 0.814895681708 0.685346918971 0.797687861272 0.730973025048 0.841315916788 0.763425253991\n",
      "200 0.85393258427 0.809233023937 0.805815672745 0.694430754066 0.816601371205 0.731635651322 0.836875926841 0.758526940188\n"
     ]
    }
   ],
   "source": [
    "######## Macro fitness \n",
    "\n",
    "def do_prediction(points, header, text):\n",
    "    points_features = [[],[]]\n",
    "    points_labels = [[],[]]\n",
    "    train_features = []\n",
    "    test_features = []\n",
    "    train_labels = []\n",
    "    test_labels = []\n",
    "    \n",
    "    shuffle(points[0])\n",
    "    shuffle(points[1])\n",
    "        \n",
    "    bound = min(len(points[0]), len(points[1]))\n",
    "    points[0] = points[0][:bound]\n",
    "    points[1] = points[1][:bound]\n",
    "    for i in range(len(points)):\n",
    "        all_labels = map(lambda x: int(x[-1]) , points[0] + points[1])\n",
    "        all_features = map(lambda x: x[:-1], points[0] + points[1])\n",
    "    points = []\n",
    "    all_features = preprocessing.scale(all_features)\n",
    "    \n",
    "    for i in range(len(all_features)):\n",
    "        points_features[all_labels[i]].append(all_features[i])\n",
    "        \n",
    "    split_points = np.random.randint(2, size=len(points_features[0]))\n",
    "    for i in range(len(split_points)):\n",
    "        if(split_points[i] == 0):\n",
    "            train_features.append(points_features[0][i])\n",
    "            train_features.append(points_features[1][i])\n",
    "            train_labels.append(0)\n",
    "            train_labels.append(1)\n",
    "        else:\n",
    "            test_features.append(points_features[0][i])\n",
    "            test_features.append(points_features[1][i])\n",
    "            test_labels.append(0)\n",
    "            test_labels.append(1)\n",
    "\n",
    "    clf = DecisionTreeClassifier()\n",
    "    clf = clf.fit(train_features, train_labels)\n",
    "    predictions = clf.predict(test_features)\n",
    "    print accuracy_score(test_labels, predictions),\n",
    "    logistic = LogisticRegression(C=1e5)\n",
    "    logistic.fit(train_features, train_labels)\n",
    "    LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
    "    fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
    "        multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
    "        solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n",
    "\n",
    "    predictions = logistic.predict(test_features) \n",
    "    temp = [\"%.5f\" % v for v in logistic.coef_[0]]\n",
    "    five_decimals = [float(i) for i in temp]\n",
    "    five_decimals_intercept = [\"%.5f\" % logistic.intercept_]\n",
    "    five_decimals = sorted(zip(header, five_decimals), key=lambda x: -abs(x[1]))\n",
    "#    print \"Coefficients: \",(five_decimals, five_decimals_intercept)\n",
    "    \n",
    "#    print accuracy_score(test_labels, predictions),\n",
    "    \n",
    "print \"k All NoSpeed OnlySpeed SpeedAndExperience\"    \n",
    "for k in range(10,201,10):\n",
    "    print k,\n",
    "    df = pd.read_csv('/home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/RawOutput/Name/PredictionFiles/k_2k_prediction_' + str(k) + '.txt')\n",
    "    df.columns = map(lambda x : x.replace(\" \", \"\") , df.columns)\n",
    "    my_copy = df.copy()\n",
    "    header = df.columns.tolist()\n",
    "\n",
    "    temp = map(list, df.values)\n",
    "    points = [[],[]]\n",
    "    for i in range(len(temp)):\n",
    "        points[int(temp[i][-1])].append(temp[i])\n",
    "    do_prediction(points, header, \"              \")\n",
    "    \n",
    "    \n",
    "    ############################################ remove all speed\n",
    "    del df['NumberOfPapers']\n",
    "    del df['HalfSpeed']\n",
    "    del df['FullSpeed']\n",
    "    header = df.columns.tolist()\n",
    "    temp = map(list, df.values)\n",
    "    points = [[],[]]\n",
    "    for i in range(len(temp)):\n",
    "        points[int(temp[i][-1])].append(temp[i])\n",
    "    do_prediction(points, header, \" Without speed features\")\n",
    "    ############################################ only speed features\n",
    "    df = my_copy[['NumberOfPapers', 'HalfSpeed', 'FullSpeed', 'Label']]\n",
    "    header = df.columns.tolist()\n",
    "    temp = map(list, df.values)\n",
    "    points = [[],[]]\n",
    "    for i in range(len(temp)):\n",
    "        points[int(temp[i][-1])].append(temp[i])\n",
    "    do_prediction(points, header, \" All speed features\")\n",
    "    ########################################## exp and speed\n",
    "    df = my_copy[['NumberOfPapers', 'HalfSpeed', 'FullSpeed', 'AvgUsingExp', \n",
    "                  'HalfAvgUsingExp', 'AvgAdoptionExp', 'HalfAvgAdoptionExp', 'Label']]\n",
    "    header = df.columns.tolist()\n",
    "    temp = map(list, df.values)\n",
    "    points = [[],[]]\n",
    "    for i in range(len(temp)):\n",
    "        points[int(temp[i][-1])].append(temp[i])\n",
    "    do_prediction(points, header, \" Speed and Experience\")\n",
    "    ######################################33\n",
    "#    df = my_copy[['AvgUsingExp', 'HalfAvgUsingExp', 'AvgAdoptionExp', 'HalfAvgAdoptionExp', 'Label']]\n",
    "#    header = df.columns.tolist()\n",
    "#    temp = map(list, df.values)\n",
    "#    points = [[],[]]\n",
    "#    for i in range(len(temp)):\n",
    "#        points[int(temp[i][-1])].append(temp[i])\n",
    "#    do_prediction(points, header, \" Speed and Experience\")\n",
    "    \n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.53557312253\n"
     ]
    }
   ],
   "source": [
    "######## author fitness \n",
    "df = pd.read_csv('/home/rahmtin/Documents/Arxiv-Feynmann/Arxiv/RawOutput/author_35_dies_before_45_or_reaches_55.txt')\n",
    "df.columns = map(lambda x : x.replace(\" \", \"\") , df.columns)\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "x= df[0:1]['ChangeFractionHighUsage']\n",
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= 0.75\n",
    "#median = np.median(df['FinalGlobalExp'].tolist())\n",
    "#print \"median: \",median\n",
    "#df['Label'] = np.where(df['FinalGlobalExp'] > median, 1, 0)\n",
    "\n",
    "train = df[df['is_train'] == True]\n",
    "test = df[df['is_train'] == False]\n",
    "#train_features = train.ix[:, df.columns.difference(['Label', 'is_train', 'FinalGlobalExp'])]\n",
    "train_features = train.ix[:, df.columns.difference(['Label', 'is_train'])]\n",
    "train_labels = train['Label']\n",
    "#test_features = test.ix[:, df.columns.difference(['Label', 'is_train','FinalGlobalExp'])]\n",
    "test_features = test.ix[:, df.columns.difference(['Label', 'is_train'])]\n",
    "test_labels = test['Label']\n",
    "\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "clf = clf.fit(train_features, train_labels)\n",
    "\n",
    "predictions = clf.predict(test_features)\n",
    "print accuracy_score(test_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
